{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reading the Kaggle excel Data\n",
    "train_rawData= sqlContext.read.format('csv').load('/FileStore/tables/train.csv',inferSchema=True,header=True)\n",
    "test_rawData= sqlContext.read.format('csv').load('/FileStore/tables/test.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert Spark DataFrame to Pandas DataFrame for easily computing mean and most frequent category value of missing value columns\n",
    "import pandas as pd\n",
    "train_rawPandas =pd.DataFrame(train_rawData.take(train_rawData.count()),columns=train_rawData.columns)\n",
    "test_rawPandas =pd.DataFrame(test_rawData.take(test_rawData.count()),columns=test_rawData.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan,isnull ,when, count\n",
    "#TrainData NullValues Fixing \n",
    "mostFrequentEmbarkValue =(train_rawPandas['Embarked'].value_counts().index[0])\n",
    "meanAge = float(train_rawPandas.Age.mean())\n",
    "nullfixedTrain_data = train_rawData.na.fill({'Age': meanAge, 'Embarked': str(mostFrequentEmbarkValue)})\n",
    "\n",
    "#TestData NullValues Fixing \n",
    "a =(test_rawPandas['Embarked'].value_counts().index[0])\n",
    "meanAge = float(test_rawPandas.Age.mean())\n",
    "nullfixedTest_data = test_rawData.na.fill({'Age': meanAge, 'Embarked': str(a)})\n",
    "\n",
    "#Confirm if data is without null entries\n",
    "nullfixedTrain_data.select([count(when(isnull(c), c)).alias(c) for c in nullfixedTrain_data.columns]).show()\n",
    "nullfixedTest_data.select([count(when(isnan(c), c)).alias(c) for c in nullfixedTest_data.columns]).show()\n",
    "#Cabin column has got null entries but I have decided to drop the column for my analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropping columns(features) with lesser siginificance on predicting Survival\n",
    "significantColumnsTrain = nullfixedTrain_data.drop('PassengerId').drop('Name').drop('Ticket').drop('Cabin')\n",
    "significantColumnsTest = nullfixedTest_data.drop('PassengerId').drop('Cabin').drop('Name').drop('Ticket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "categoricalFeatures = [\"Sex\", \"Embarked\"]\n",
    "stages = [] # stages in our Pipeline\n",
    "for categoricalCol in categoricalFeatures:\n",
    "  # Category Indexing with StringIndexer\n",
    "  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n",
    "  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n",
    "  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n",
    "  # Add stages.  These are not run here, but will run all at once later on.\n",
    "  stages += [stringIndexer, encoder]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numericCols = [\"Pclass\",\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "assemblerInputs = map(lambda c: c + \"classVec\", categoricalFeatures) + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a Pipeline.\n",
    "pipeline = Pipeline(stages=stages)\n",
    "# Run the feature transformations.\n",
    "#  - fit() computes feature statistics as needed.\n",
    "#  - transform() actually transforms the features.\n",
    "pipelineModel = pipeline.fit(significantColumnsTrain)\n",
    "processedTrain = pipelineModel.transform(significantColumnsTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Splitting Data to compare performance of classifiers\n",
    "(PerformanceMetricTrainData, PerformanceMetricTestData) = processedTrain.randomSplit([0.8, 0.2], seed = 100)\n",
    "print PerformanceMetricTrainData.count()\n",
    "print PerformanceMetricTestData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Create initial LogisticRegression model\n",
    "lr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\", maxIter=10)\n",
    "# Train model with Training Data\n",
    "lrModel = lr.fit(PerformanceMetricTrainData)\n",
    "#Transform/Predict on remaining trainingData from 70-30 split\n",
    "predictionsLR = lrModel.transform(PerformanceMetricTestData)\n",
    "#predictionsLR.select('rawPrediction').show(89,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "#fitting the data\n",
    "dtModel = DecisionTreeClassifier(maxDepth=4,labelCol='Survived').fit(PerformanceMetricTrainData)\n",
    "predictionsDT =dtModel.transform(PerformanceMetricTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rfModel = RandomForestClassifier(numTrees = 100, labelCol = 'Survived').fit(PerformanceMetricTrainData)\n",
    "predictionsRF = rfModel.transform(PerformanceMetricTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Multi-layer Perceptron\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassificationModel\n",
    "layer = [8,6,7,2]\n",
    "mcP = MultilayerPerceptronClassifier(labelCol = 'Survived',maxIter=100, layers=layer, blockSize=128,seed=1234)\n",
    "# train the model\n",
    "mcPmodel = mcP.fit(PerformanceMetricTrainData)\n",
    "\n",
    "# Predict label on the test set\n",
    "mcPresult = mcPmodel.transform(PerformanceMetricTestData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator,MulticlassClassificationEvaluator\n",
    "predictionsLR.withColumn(\"label\",predictionsLR.Survived.cast('double')).select(\"label\",\"prediction\")\n",
    "binaryClassEvaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol=\"Survived\")\n",
    "LRmetric = binaryClassEvaluator.evaluate(predictionsLR)\n",
    "DTmetric = binaryClassEvaluator.evaluate(predictionsDT)\n",
    "RFmetric = binaryClassEvaluator.evaluate(predictionsRF)\n",
    "mlPCmetric = binaryClassEvaluator.evaluate(mcPresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeAccuracy(act,pre):\n",
    "  #check if length of lists are equal\n",
    "  if(len(act) != len(pre)):\n",
    "    return 'Lists are of different size'\n",
    "  length = len(act) #can also use predicted lists\n",
    "  hit = 0\n",
    "  for i in range(length):\n",
    "    if act[i] == pre[i]:\n",
    "      hit += 1\n",
    "  accuracy = float(hit)/float(length)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareAccuracyList1(actuals,predicted):\n",
    "  actuals_array = [float(i.Survived) for i in actuals]\n",
    "  predicted_array = [float(i.prediction) for i in predicted]\n",
    "  return actuals_array,predicted_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actualsLR = predictionsLR.select('Survived').collect()\n",
    "predictedLR = predictionsLR.select('prediction').collect()\n",
    "actualsDT = predictionsDT.select('Survived').collect()\n",
    "predictedDT = predictionsDT.select('prediction').collect()\n",
    "actualsRF = predictionsRF.select('Survived').collect()\n",
    "predictedRF = predictionsRF.select('prediction').collect()\n",
    "actualsMultilayer = mcPresult.select('Survived').collect()\n",
    "predictedMultilayer = mcPresult.select('prediction').collect()\n",
    "\n",
    "actualsLRList,predictedLRList =prepareAccuracyList1(actualsLR,predictedLR)\n",
    "actualsDTList,predictedDTList =prepareAccuracyList1(actualsDT,predictedDT)\n",
    "actualsRFList,predictedRFList =prepareAccuracyList1(actualsRF,predictedRF)\n",
    "actualsMLCPList,predictedMLCPList =prepareAccuracyList1(actualsMultilayer,predictedMultilayer)\n",
    "\n",
    "\n",
    "\n",
    "accuracyLR = computeAccuracy(actualsLRList,predictedLRList)\n",
    "accuracyDT = computeAccuracy(actualsDTList,predictedDTList)\n",
    "accuracyRF = computeAccuracy(actualsRFList,predictedRFList)\n",
    "accuracyMLP =computeAccuracy(actualsMLCPList,predictedMLCPList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame([\n",
    "    (\"Logistic Regression\",accuracyLR, LRmetric),\n",
    "    (\"DecisionTree\", accuracyDT,DTmetric),\n",
    "    (\"RandomForest\",accuracyRF,RFmetric),\n",
    "    (\"MultilayerPerceptronClassifier\",accuracyMLP,mlPCmetric),\n",
    "], [\"Classifier\", \"accuracy\",binaryClassEvaluator.getMetricName()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df1.show(truncate=False)\n",
    "display(df1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "muthuBigDataAnalyticsAssignment2",
  "notebookId": 142953995028596
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
